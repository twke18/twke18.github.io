<!DOCTYPE html>
<html>
<head>
    <title>Tsung-Wei Ke</title>

    <!-- Meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Styles -->
    <style>
          body {
            font-family: Roboto, 'sans-serif';
            font-size: 16px;
            background-color: #FFFFFF;
            color: #4F6071;
          }
          h1 {
              font-weight: 300;
              font-size: 2rem;
          }
          #header {
            background-color: #f4f4f4;
            /*background-color: #FFFFFF;*/
            display: flex;
            align-items: flex-end;
            padding-top:60px;
            padding-bottom:60px;
          }
          #footer {
            background-color: #FFFFFF;
            padding:60px;
          }
          #portrait {
            border: 3px solid white;
          }
          #header-text {
            margin-top: 60px;
            margin-left: 220px;
          }
          #header-text-name {
            font-size: 40px;
          }
          #header-text-title {
              font-size: 17px;
          }
          #header-text-affiliation {
              font-size: 17px;
              margin-top: 10px;
          }
          #header-text-email {
            margin-top: 10px;
            font-size: 17px;
            font-style: italic;
          }
          .header-text-desc {
            font-size: 20px;
          }
          .vspace-top {
            margin-top: 30px;
          }
          .vspace-top-news {
              margin-top: 15px;
          }
          .paper-image {
            width: 150px;
          }
          .news-date {
              font-weight: bold;
          }
          .paper-title {
            font-weight: bold;
          }
          .paper-authors {
            font-style: italic;
          }
    </style>
</head>

<body>
    <div id='header'>
        <div class='container'>
            <div class='row'>
                <div class="col-sm-3 offset-sm-1">
                    <img src='img/profile.png' class='img-fluid' id='portrait'>
                </div>

                <div class="col">
                  <div id='header-text-name'>
                    Tsung-Wei Ke
                  </div>
                  <div id='header-text-title'>
                      Assistant Professor
                      <!-- Principal investigator, Embodied Artificial Intelligence Lab -->
                  </div>
                  <div id='header-text-affiliation'>
                    NTU Department of <a href="https://www.csie.ntu.edu.tw">Computer Science</a>
                  </div>

                  <div id='head-text-title'>
                    <br>
                    I am an Assistant Professor at NTU CSIE, where I am leading the Embodied Artificial Intelligence Lab. 
                    Before joining NTU, I spent two years as a postdoc at CMU MLD, working with <a href="https://www.cs.cmu.edu/~katef/">Katerina Fragkiadaki</a>.
                    During 2018-2022, I have closely worked with <a href="https://web.eecs.umich.edu/~stellayu/">Stella Yu</a> for my Ph.D at UC Berkeley VS Program.
                  </div>

                  <div id='header-text-email'>
                        twke (at) csie (dot) ntu (dot) edu (dot) tw
                  </div>
                  <div>
                    <a href="https://github.com/twke18">[GitHub]</a>
                    <a href="https://scholar.google.com/citations?user=WTEFsHMAAAAJ&hl=en&oi=ao">[Google Scholar]</a>
                    <a href="pdfs/cv.pdf">[Download CV]</a>
                  </div>
                </div>
            </div>
        </div>
    </div>


    <div class='container'>
        <div class='row vspace-top'>
            <div class='col offset-sm-1'>


                <h1>Research</h1>
                I am interested in the trio of action, perception, and cognition.  More particularly, I have been hoping
                to build machines that perceives to recognize the real world, understands the (physical) outcomes of their
                actions, explores novel complex behaviors, and learns/plans to achieve goals.  I am fascinated by the
                animal beings that generalize and explore so successfully (see <a href="https://en.wikipedia.org/wiki/Moravec%27s_paradox">Moravec's Paradox</a>).

                <div class='vspace-top'>
                <h5>Prospective students</h5>
                I am looking for Ph.D/master/undergraduate students interested in robot learning, computer vision and
                machine learning.  If you are a undergraduate at NTU, interested in research positions, please fill in
                this <a href="https://forms.gle/W7rSPF9cM3C5jaZV8">form</a>.  If you are interested in Mater/Doctoral
                research positions, please fill in this <a href="https://forms.gle/JxzbmXpEAPqp6jkf8">form</a>.
                </div>

                <div class='vspace-top'>
                    <h1>Teaching</h1>
                </div>
                <a href="https://ntu-rpl.github.io/">CSIE5117: Robot Perception and Learning</a> Fall 2024, 2025<br>
                <a href="">CSIE5421: Embodied Vision</a> Spring 2025

                <div class='vspace-top'>
                    <h1>Publications</h1>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                       <img src='img/pubs/spf_corl2025.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation
                        </div>
                        <div class='paper-desc'>
                            CoRL 2025
                        </div>
                        <div class='paper-authors'>
                            Chih Yao Hu*, Yang-Sen Lin*, Yuna Lee, Chih-Hai Su, Jie-Ying Lee, Shr-Ruei Tsai, Chin-Yang Lin, Kuan-Wen Chen, Tsung-Wei Ke, Yu-Lun Liu
                        </div>
                        <div>
                            <a href="">[Arxiv](TBA)</a>
                            <a href="">[Code](TBA)</a>
                            <a href="https://spf-web.pages.dev/">[Project]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                       <img src='img/pubs/diffact_arxiv.jpg' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            3D Diffuser Actor: Policy Diffusion with 3D Scene Representations
                        </div>
                        <div class='paper-desc'>
                            CoRL 2024
                        </div>
                        <div class='paper-authors'>
                            Tsung-Wei Ke*, Nikolaos Gkanatsios*, and Katerina Fragkiadaki
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/2402.10885">[Arxiv]</a>
                            <a href="https://github.com/nickgkan/3d_diffuser_actor">[Code]</a>
                            <a href="https://3d-diffuser-actor.github.io">[Project]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                       <img src='img/pubs/diffes_arxiv.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous and Instruction-guided Driving
                        </div>
                        <div class='paper-desc'>
                            CVPR 2024
                        </div>
                        <div class='paper-authors'>
                            Brian Yang, Huangyuan Su, Nikolaos Gkanatsios, Tsung-Wei Ke, Ayush Jain, Jeff Schneider, and Katerina Fragkiadaki <br>
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/2402.06559">[Arxiv]</a>
                            <a href="https://github.com/bhyang/diffusion-es">[Code]</a>
                            <a href="https://diffusion-es.github.io/">[Project]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                       <img src='img/pubs/cast_iclr2024.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Learning Hierarchical Image Segmentation For Recognition and By Recognition<
                        </div>
                        <div class='paper-desc'>
                            ICLR 2024 (Spotlight)
                        </div>
                        <div class='paper-authors'>
                            Tsung-Wei Ke*, Sangwoo Mo*, and Stella Yu
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/2210.00314">[Arxiv]</a>
                            <a href="https://github.com/twke18/CAST">[Code]</a>
                            <a href="https://CAST-vision.github.io/">[Project]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                       <img src='img/pubs/tta_neurips2023.gif' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Test time Adaptation with Diffusion Models
                        </div>
                        <div class='paper-desc'>
                            NeuRIPS 2023
                        </div>
                        <div class='paper-authors'>
                            Mihir Prabhudesai*, Tsung-Wei Ke*, Alexander Cong Li, Deepak Pathak and Katerina Fragkiadaki
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/2311.16102">[Arxiv]</a>
                            <a href="https://github.com/mihirp1998/Diffusion-TTA">[Code]</a>
                            <a href="https://diffusion-tta.github.io/">[Project]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                       <img src='img/pubs/hsg_cvpr2022.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Unsupervised Hierarchical Semantic Segmentation with Multiview Cosegmentation and Clustering Transformers
                        </div>
                        <div class='paper-desc'>
                            CVPR 2022 (Oral)
                        </div>
                        <div class='paper-authors'>
                            Tsung-Wei Ke, Jyh-Jing Hwang, Yunhui Guo, Xudong Wang and Stella X. Yu
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/2204.11432">[Arxiv]</a>
                            <a href="https://github.com/twke18/HSG">[Code]</a>
                            <a href="https://twke18.github.io/projects/hsg.html">[Project]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                       <img src='img/pubs/spml_iclr2021.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Universal Weakly Supervised Segmentation by Pixel-to-Segment Contrastive Learning
                        </div>
                        <div class='paper-desc'>
                            ICLR 2021
                        </div>
                        <div class='paper-authors'>
                            Tsung-Wei Ke, Jyh-Jing Hwang, and Stella X. Yu
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/2105.00957">[Arxiv]</a>
                            <a href="https://github.com/twke18/SPML">[Code]</a>
                            <a href="https://twke18.github.io/projects/spml.html">[Project]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                       <img src='img/pubs/asm_cvpr2019.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Adversarial Structure Matching for Structured Prediction Tasks
                        </div>
                        <div class='paper-desc'>
                            CVPR 2019
                        </div>
                        <div class='paper-authors'>
                            Jyh-Jing Hwang, Tsung-Wei Ke, Jianbo Shi and Stella X. Yu
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/1805.07457">[Arxiv]</a>
                            <a href="https://github.com/twke18/Adversarial_Structure_Matching">[Code]</a>
                            <a href="https://jyhjinghwang.github.io/projects/asm.html">[Project]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                       <img src='img/pubs/aaf_eccv2018.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Adaptive Affinity Field for Semantic Segmentation
                        </div>
                        <div class='paper-desc'>
                            ECCV 2018
                        </div>
                        <div class='paper-authors'>
                            Tsung-Wei Ke*, Jyh-Jing Hwang*, Ziwei Liu and Stella X. Yu (*equal contribution)
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/1803.10335">[Arxiv]</a>
                            <a href="https://github.com/twke18/Adaptive_Affinity_Fields">[Code]</a>
                            <a href="https://jyhjinghwang.github.io/projects/aaf.html">[Project]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                       <img src='img/pubs/nmg_cvpr2017.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Neural MultiGrid
                        </div>
                        <div class='paper-desc'>
                            CVPR 2017
                        </div>
                        <div class='paper-authors'>
                            Tsung-Wei Ke, Michael Maire, and Stella X. Yu
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/1611.07661"">[Arxiv]</a>
                            <a href="https://github.com/buttomnutstoast/Neural-MultiGrid">[Code]</a>
                        </div>
                    </div>
                </div>

            </div>
        </div>
    </div>


    <div id='footer' class='vspace-top'>
    <div>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
</body>

</html>
